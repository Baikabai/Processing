# Processing
# Suzuki-Ibaraki_University

For all of the students in the Suzuki_lab in Ibaraki University.
I am Luo, the Second year of master's degree.I interested in Computer Science.I am doing research on natural language processing(NLP)


Segmentation.py

Use the code to segementate the txt file.
![image](https://user-images.githubusercontent.com/49239360/163093541-6f6e89dd-24a7-408c-b3ca-ea0e9957b846.png)
to
![image](https://user-images.githubusercontent.com/49239360/163093593-bd3eece5-99a1-4836-a834-c73349c08489.png)


frequency of occurrence.py
frequency of occurrence in livedoor-news and wiki40b Top100
![code](https://user-images.githubusercontent.com/49239360/163103615-65657c00-93f3-4c28-9e5b-a971a1f3b5d3.png)


Stopwords_use.py section_paragraph.py remove_spaces.py remove_spacein.py 

Firstly,use the Stopwords_use.py,then use the section_paragraph.py,then use the remove_spacein.py,lastly,use the remove_spaces.py. Therefore, you can get the data.
for example, we use the livedoor-news and wiki40b/ja
![image](https://user-images.githubusercontent.com/49239360/163121629-387e6cd2-c5d6-471e-af7c-aab2804a19f2.png)

word2vec_training.py word2vec_use.py

You can use the word2vec_training.py to train the word2vec_model.Then you can use the word2vec_use.py to find the word vector.
![image](https://user-images.githubusercontent.com/49239360/163155936-0f301c9f-6f72-499a-ae00-9d1fba220c51.png)

![result of two words](https://user-images.githubusercontent.com/49239360/163155866-a5aa845b-d969-4812-a6c6-c0f25a3b4c2c.png)

